#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
__title__ = KNN
__author__ = 'Administrator'
__mtime__ = '2018/4/19'
# code is far away from bugs with the god animal protecting
    I love animals. They taste delicious.
              ┏┓      ┏┓
            ┏┛┻━━━┛┻┓
            ┃      ☃      ┃
            ┃  ┳┛  ┗┳  ┃
            ┃      ┻      ┃
            ┗━┓      ┏━┛
                ┃      ┗━━━┓
                ┃  神兽保佑    ┣┓
                ┃　永无BUG！   ┏┛
                ┗┓┓┏━┳┓┏┛
                  ┃┫┫  ┃┫┫
                  ┗┻┛  ┗┻┛
"""
import math
"""KNN
    一句话总计：近朱者赤 近墨者黑
    input:  
            经过预处理的特征向量
            对应于特征空间的点 --- 多个类
            监督分析算法
            分类时通过多数表决进行预测
            k近邻算法--没有训练过程 
                    --不具有显式的学程
            
    基本要素:
            k值的选择
            距离度量
            分类决策规则
    
    案列:
            爱情片和动作片分类
    数学原理:
            欧式距离
            计算未知与已知之间的距离
            相似度越高距离越小
            相似度越低距离越大
            k:  是自己设置的数
    训练时间为0 计算时间很多
    k值:
            交叉验证优化
    优缺点:
        缺点:
            k值小了 容易过拟合 分得过于细了
        k值大了
            可以避免过拟合
            对最终结果可能有影响
        缺点:
        
            
    分类决策规则：
            knn中求取分类最优近邻 是合理的
            距离加权
                距离近权重加大
                距离远权重减小
    
    # 学习误差: 
    # 估计误差: 模型估计值与实际之间的差距   训练
    # 近似误差: 模型估值与实际差距          测试集 
    消除数据的量纲大小影响---做无量纲化优化
    归一化:AutoNorm
        将你需要处理的数据经过处理限制在一定条件范围内
            方法：
                1.线性函数转化[0, 1]
                2.对数函数转化
                3.反余切函数转化
                4.输入值转为[-1, 1]
    样本数据分解:
        0.1 训练数据
        0.9 测试数据
        总体样本数据    
        
    用于回归:
        k个近邻的平均值
        
"""


"""knn 距离加权的几种方式
    1. 反函数
        该方法最简单的形式是返回距离的倒数 完全一样或非常接近的商品权重为会很大
        因此: 在距离求倒数时 在距离上加一个常量
        比如距离D 权重为:1/D
        weigh = 1/(distance + const)
      缺点: 为近邻分配很大的权重 使得算法对噪声数据变得敏感
    2.高斯函数(正态分布)
        高斯函数在距离为0的时候权重为1，随着距离增大，权重减少，但不会变为0
        

    计算加权knn
    1.在处理离散型数据时，将这k个数据用权重区别对待，预测结果与第n个数据的label相同的概率
    2.在处理数值型数据时，并不是对这k个数据简单的求平均，而是加权平均：通过将每一项的距离值乘以对应权重，让后将结果累加。求出总和后，在对其除以所有权重之和。
    
"""
# 高斯函数实现方式
def gaussian(dist, a=1, b=0, c=0.3):
    return a * math.e ** (-(dist - b) ** 2 / (2 * c ** 2))























