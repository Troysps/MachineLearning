晚上上传

统计学
数据分析
meachine learning


4 multiple features
特征数量:n = number of features
样本数量:m = number of samples

特征向量 x^(i)  i^th features matrix


特征缩放
	假设x1 [0, 2000]
		x2 [1, 5]
		
		
	代价函数的图像会变成椭圆形
	梯度下降会变得很慢
	
	
	使用特征缩放 --归一化数值 特征处理 无量纲化数据
	
	一般来说特征缩放是 将数据取值范围 [-1, 1] 稍微大一些也可以
	
	针对不同的情况进行不同的缩放 -- 让数据足够的接近
	
	数据归一化
	
	x1 = x1- u1/s1
	
	u1 数据集中特征x1的均值
	s1 数据集中特征x1的最大值
	feature scaling
	
	
梯度下降--实用技巧 如何确定 学习速率

	确定梯度下降的次数 循环次数
	
	需要多个步迭代
	
	
	检测代价函数是否自动收敛
	
	如果代价函数不断增加 使用较小的学习速率
	
	总结: 	alpha small slow convergence
			alpha large not decrease
		
	选择alpha 0.001 0.001*3 0.01 ...
	
	
选择特征
	有时候使用新的特征可能效果更好
	多项式回归  --选择特征 直线不能很好的拟合模型
	
	多项式拟合数据
		将一个三次函数拟合到模型中
		不同的特征选择
		根据不同数据的情况使用不同的特征 甚至可以开根号
		
		
		
	
	基函数扩展线性模型	https://blog.csdn.net/voidfaceless/article/details/62215265
	
	
	标准方程法
		
	
	
	
	